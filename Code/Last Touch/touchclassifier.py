# -*- coding: utf-8 -*-
"""TouchClassifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/126Z1Nma9ek6geVx96CyUdZG_fxxkjoE7
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sn
import statistics
# This library is needed to save RF model
import joblib

# I need to use this version because Matlab has this version as well
!pip install scikit-learn==1.3.0

dataset = pd.read_csv('/content/NewDataset.csv')

dataset[0]

"""## Data Preprocessing

"""

row_number, col_number = dataset.shape
print(f'The dataset contains {row_number} rows and {col_number} columns.')

dataset.info()

# Check for duplicate values
dataset[dataset.duplicated()]
# or  dataset[dataset.duplicated()].sum()

"""As we can see above, there isn't any duplicated record in the dataset."""

# Check missing values
null_columns = dataset.columns[dataset.isnull().any()]

print('List of columns consisting null values and their quantity:')
print(dataset[null_columns].isnull().sum())

"""There is no missing values in this dataset.

**Data Distribution**

Here, the distribution of the values in each column of the dataset is shown.
"""

fig=plt.figure(figsize=(20,25))

for index, column in enumerate(dataset.columns):
    ax = fig.add_subplot(6,3,index+1)
    dataset[column].hist(bins = 20, ax = ax, facecolor = 'LightSeaGreen')
    ax.set_title(column + " distribution",color = 'darkred')

fig.tight_layout()
plt.show()

"""**Check Correlation**

Showing the correlation between the features using a heatmap.
"""

sn.pairplot(dataset, hue='Touch')

"""**Checking Balancing**"""

dataset.Touch.value_counts()

sn.countplot(x='Touch',data=dataset,palette=["#eb383b","#3853eb"])

"""**Learning and Model Selection**"""

# Separating target feature from the features
y = dataset['Touch']
X = dataset.drop(columns=['Touch'], axis=1)

from sklearn.model_selection import train_test_split
import random

# divide train test: 60 % - 20 % - 20%
X_, X_test, y_, y_test = train_test_split(X, y, test_size = 0.20, random_state= 21)
X_train, X_validation, y_train, y_validation = train_test_split(X_, y_, test_size = 0.20, random_state= 21)

"""**Random Forest**"""

# Random Forest
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
classifierRF = RandomForestClassifier(max_depth= 15,n_estimators=20)
classifierRF.fit(X_train, y_train)
y_pred_val_RF = classifierRF.predict(X_validation)
print("************Results for Random Forest*************")
print("Confusion Matrix for Validation Set\n")
print(classification_report(y_validation, y_pred_val_RF))

# Random Forest
from sklearn.ensemble import RandomForestClassifier
classifierRF = RandomForestClassifier(max_depth= 15,n_estimators=20)
classifierRF.fit(X_train, y_train)
y_pred_test_RF = classifierRF.predict(X_test)
print("************Results for Random Forest*************")
print("Confusion Matrix for test Set\n")
print(classification_report(y_test, y_pred_test_RF))

"""pridict for different unseen data - 12-03-2024"""

#  Define a function for feature extracting
def feature_extractor(file):
    # Reading Data
    data = pd.read_csv(file)
    # Choosing the ball and the turtle positions
    targeted_columns = data.iloc[1:, [5,6,7,12,13,14]][4:]
    # Define a header
    targeted_columns.columns=['X_Ball', 'Y_Ball', 'Z_Ball', 'X_Turtle', 'Y_Turtle', 'Z_Turtle']
    # Delete missing Values
    targeted_columns = targeted_columns.dropna()
    # Reset the index of the DataFrame
    targeted_columns = targeted_columns.reset_index(drop=True)
    cleaned_data = targeted_columns
    cleaned_data = cleaned_data.apply(pd.to_numeric)
    cleaned_data['X_dist']= cleaned_data['X_Ball'] - cleaned_data['X_Turtle']
    cleaned_data['Y_dist']= cleaned_data['Y_Ball'] - cleaned_data['Y_Turtle']
    cleaned_data['Z_dist']= cleaned_data['Z_Ball'] - cleaned_data['Z_Turtle']
    cleaned_data['distance'] =  np.sqrt(cleaned_data['X_dist']**2 + cleaned_data['Y_dist']**2 + cleaned_data['Z_dist']**2)
    return cleaned_data

"""**First Sample**"""

test_data = feature_extractor('/content/NoTouch1.csv')

test_data

test_data['Touch'] = 1
test_data

test_data_x = test_data.drop(columns=['Touch'], axis=1)
test_data_y = test_data['Touch']

test_data_x.shape

y_predRF_test = classifierRF.predict(test_data_x.iloc[[1000]])
y_predRF_test

"""**Saving RF Model**"""

joblib.dump(classifierRF, "RFClassifier")

RF_Classifier = joblib.load("RFClassifier")

y_predRF_test = RF_Classifier.predict(test_data_x.iloc[[4]])
y_predRF_test